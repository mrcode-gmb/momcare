{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Q&A Bot - Computer Programming\n",
    "This notebook loads a Q&A dataset, builds a simple retrieval model using TF-IDF and cosine similarity, and allows you to ask questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the Restaurant Q&A Dataset\n",
    "\n",
    "In this step, we import the pandas library and load the restaurant dataset (`restaurant_qa_10k.csv`) into a DataFrame called `df`.\n",
    "We then display the first 5 rows to understand the structure of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What should I do if I have a stomach ache?</td>\n",
       "      <td>Drink plenty of water, rest well, and avoid he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I reduce a fever?</td>\n",
       "      <td>Rest well, drink plenty of water, and you can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What prevents a baby from sleeping at night?</td>\n",
       "      <td>A baby may not sleep due to hunger, stomach ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Should I vaccinate my baby?</td>\n",
       "      <td>Yes, it is important to vaccinate your baby ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What prevents a woman from getting pregnant?</td>\n",
       "      <td>Causes include hormonal problems, uterine prob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Question  \\\n",
       "0    What should I do if I have a stomach ache?   \n",
       "1                     How can I reduce a fever?   \n",
       "2  What prevents a baby from sleeping at night?   \n",
       "3                   Should I vaccinate my baby?   \n",
       "4  What prevents a woman from getting pregnant?   \n",
       "\n",
       "                                              Answer  \n",
       "0  Drink plenty of water, rest well, and avoid he...  \n",
       "1  Rest well, drink plenty of water, and you can ...  \n",
       "2  A baby may not sleep due to hunger, stomach ac...  \n",
       "3  Yes, it is important to vaccinate your baby ac...  \n",
       "4  Causes include hormonal problems, uterine prob...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the restaurant dataset\n",
    "df = pd.read_csv('combined_knowledge_base.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Split the Dataset into Training and Testing Sets\n",
    "\n",
    "We use `train_test_split` from `sklearn.model_selection` to split the dataset:\n",
    "- 90% of the data is used for training (`train_df`)\n",
    "- 10% of the data is used for testing (`test_df`)\n",
    "Setting `random_state=42` ensures that the split is reproducible.\n",
    "We then check the shapes of the resulting training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216 entries, 0 to 215\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  216 non-null    object\n",
      " 1   Answer    216 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((194, 2), (22, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 90% Train / 10% Test\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_df.shape, test_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load the Pre-trained SentenceTransformer Model\n",
    "\n",
    "We load the `all-MiniLM-L6-v2` model from the `sentence_transformers` library.\n",
    "- This model is small but very efficient for generating sentence embeddings.\n",
    "- It will help convert questions and answers into vector representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load small but powerful model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare Training Data and Loss Function\n",
    "\n",
    "- We create `InputExample` objects for each question-answer pair from the training dataset.\n",
    "- The `label=0.9` means we expect a high similarity between the question and its correct answer.\n",
    "- We use a `DataLoader` to efficiently load the data during training, shuffling it and using a batch size of 32.\n",
    "- We define the **Cosine Similarity Loss**, which will train the model to bring similar question-answer pairs closer in vector space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples\n",
    "train_examples = [InputExample(texts=[row['Question'], row['Answer']],label=0.9) for idx, row in train_df.iterrows()]\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "\n",
    "# Define Cosine Similarity Loss\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fine-tuning the Model\n",
    "\n",
    "- We fine-tune the pre-trained SentenceTransformer model using our restaurant dataset.\n",
    "- `train_objectives` specifies the training data and loss function.\n",
    "- `epochs=1` means the model will see the entire training dataset once (can be increased for better accuracy).\n",
    "- `warmup_steps=100` helps the model stabilize during the early training phase.\n",
    "- `show_progress_bar=True` displays a progress bar to monitor training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4195f161242439daef4fadd9422d2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,  # You can increase to 2â€“5 epochs for better results\n",
    "    warmup_steps=100,\n",
    "    show_progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Encode the Questions into Embeddings\n",
    "\n",
    "- We use the fine-tuned model to **convert** all training and testing questions into **vector embeddings**.\n",
    "- `convert_to_tensor=True` ensures that the embeddings are stored as PyTorch tensors, which are efficient for similarity computation later.\n",
    "- These embeddings will help the model find the most relevant answers during prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode questions into embeddings\n",
    "train_embeddings = model.encode(train_df['Question'].tolist(), convert_to_tensor=True)\n",
    "test_embeddings = model.encode(test_df['Question'].tolist(), convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate the Model Performance\n",
    "\n",
    "- We define an `evaluate` function to check how well the model retrieves the correct answers.\n",
    "- **Process**:\n",
    "  - For each question in the test set:\n",
    "    - Encode the question.\n",
    "    - Compute **cosine similarity** with all training questions.\n",
    "    - Find the top 3 most similar questions.\n",
    "    - Check if the expected answer is among the top retrieved results.\n",
    "- **Metrics**:\n",
    "  - **Top-1 Accuracy**: Correct answer is the first most similar prediction.\n",
    "  - **Top-3 Accuracy**: Correct answer is among the top 3 predictions.\n",
    "- Finally, we print the evaluation results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.00\n",
      "Top-3 Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "import torch\n",
    "\n",
    "def evaluate(test_df, train_df, train_embeddings, model, top_k=3):\n",
    "    correct_top1 = 0\n",
    "    correct_top3 = 0\n",
    "\n",
    "    for idx, row in test_df.iterrows():\n",
    "        query = row['Question']\n",
    "        expected_answer = row['Answer']\n",
    "        \n",
    "        query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "        scores = cos_sim(query_embedding, train_embeddings)[0]\n",
    "        top_results = torch.topk(scores, k=top_k)\n",
    "        \n",
    "        found = False\n",
    "        for score_idx in top_results.indices:\n",
    "            candidate_answer = train_df.iloc[score_idx.item()]['Answer']\n",
    "            if candidate_answer == expected_answer:\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if top_results.indices[0] == idx:\n",
    "            correct_top1 += 1\n",
    "        if found:\n",
    "            correct_top3 += 1\n",
    "\n",
    "    top1_acc = correct_top1 / len(test_df)\n",
    "    top3_acc = correct_top3 / len(test_df)\n",
    "    \n",
    "    return top1_acc, top3_acc\n",
    "\n",
    "# Run evaluation\n",
    "top1_acc, top3_acc = evaluate(test_df, train_df, train_embeddings, model)\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.2f}\")\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Define Chatbot Response Function\n",
    "\n",
    "- In this step, we define a function `chatbot_response()` to simulate a query-response mechanism.\n",
    "- The function:\n",
    "  - Takes a user query as input and converts it into an embedding.\n",
    "  - Uses `semantic_search()` to find the top `n` similar questions from the training data.\n",
    "  - Prints the matched question, answer, and the similarity score.\n",
    "- In this case, we're testing the chatbot with the query `\"ji\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library if not already imported\n",
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "# Define function to test the model\n",
    "def chatbot_response(user_query, top_n=3):\n",
    "    user_embedding = model.encode(user_query, convert_to_tensor=True)\n",
    "    hits = semantic_search(user_embedding, train_embeddings, top_k=top_n)[0]\n",
    "    \n",
    "    for hit in hits:\n",
    "        idx = hit['corpus_id']\n",
    "        matched_question = train_df.iloc[idx]['Question']\n",
    "        answer = train_df.iloc[idx]['Answer']\n",
    "        score = hit['score']\n",
    "        \n",
    "        print(f\"Matched Question: {matched_question}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(f\"Similarity Score: {score:.2f}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Define Chatbot Response Function And test here\n",
    "\n",
    "- In this case, we're testing the chatbot with the query `\"ji\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Question: Hello\n",
      "Answer: Hello! How can I assist you today?\n",
      "Similarity Score: 0.71\n",
      "--------------------------------------------------\n",
      "Matched Question: Hey\n",
      "Answer: Hey there! How can I help you today?\n",
      "Similarity Score: 0.70\n",
      "--------------------------------------------------\n",
      "Matched Question: What is the benefit of taking a warm bath after childbirth?\n",
      "Answer: A warm bath relieves pain, improves blood circulation, and helps the body recover after childbirth.\n",
      "Similarity Score: 0.20\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chatbot_response(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Save the Model Using Pickle\n",
    "\n",
    "- Here, we save the entire trained model as a `.pkl` file using **Pickle**.\n",
    "- The model is saved as `'restaurant_chatbot_model.pkl'`.\n",
    "- This allows us to load and use the model later in other projects or environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"momcare_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as restaurant_chatbot_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the whole model\n",
    "with open('momcare.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model saved as restaurant_chatbot_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
